# ALGORITHMIC ARTS ‚Äî –£–ª—É—á—à–µ–Ω–Ω—ã–µ –ü—Ä–æ–º–ø—Ç—ã ‚Ññ1 –∏ ‚Ññ2

**–í–µ—Ä—Å–∏—è:** 3.1 (Enhanced)  
**–î–∞—Ç–∞:** –§–µ–≤—Ä–∞–ª—å 2026  
**–°—Ç–∞—Ç—É—Å:** Production Ready  

> –†–∞—Å—à–∏—Ä–µ–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è –ø—Ä–æ–º–ø—Ç–æ–≤ ‚Ññ1 –∏ ‚Ññ2 –∏–∑ `PROMPTS_FOR_QWEN.md`.  
> –î–æ–±–∞–≤–ª–µ–Ω—ã: –ø–æ–ª–Ω–∞—è —Ñ–∞–π–ª–æ–≤–∞—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∞ —Å –ø–µ—Ä–µ—á–Ω–µ–º –∫–∞–∂–¥–æ–≥–æ —Ñ–∞–π–ª–∞, –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ Dockerfile (multi-stage), –ø–æ–ª–Ω—ã–π `.env.example`, —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π Makefile —Å–æ –≤—Å–µ–º–∏ –∫–æ–º–∞–Ω–¥–∞–º–∏, —Å–∫—Ä–∏–ø—Ç—ã –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Å–µ–∫—Ä–µ—Ç–æ–≤. –í –ø—Ä–æ–º–ø—Ç–µ ‚Ññ2 ‚Äî SQL DDL —Å–æ –≤—Å–µ–º–∏ –∏–Ω–¥–µ–∫—Å–∞–º–∏, —Ç—Ä–∏–≥–≥–µ—Ä–∞–º–∏ –∏ –ø–∞—Ä—Ç–∏—Ü–∏–æ–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ–º, Alembic-–º–∏–≥—Ä–∞—Ü–∏–∏ —Å —Ä–µ–∞–ª—å–Ω—ã–º –∫–æ–¥–æ–º, SQLAlchemy 2.0 (Mapped-—Å–∏–Ω—Ç–∞–∫—Å–∏—Å), ClickHouse-—Å—Ö–µ–º–∞ –∏ seed-—Å–∫—Ä–∏–ø—Ç.

---

## –ü—Ä–æ–º–ø—Ç ‚Ññ1: –ò–Ω—Ñ—Ä–∞—Å—Ç—Ä—É–∫—Ç—É—Ä–∞ (–†–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π)

### –ó–∞–¥–∞—á–∞
–°–æ–∑–¥–∞—Ç—å –ø–æ–ª–Ω—É—é –∏–Ω—Ñ—Ä–∞—Å—Ç—Ä—É–∫—Ç—É—Ä—É –ø—Ä–æ–µ–∫—Ç–∞: —Å—Ç—Ä—É–∫—Ç—É—Ä—É –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–π, Docker Compose, Dockerfile –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —Å–µ—Ä–≤–∏—Å–∞, `.env.example`, Makefile, —Å–∫—Ä–∏–ø—Ç—ã –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏.

### –ü—Ä–æ–º–ø—Ç

```markdown
–°–æ–∑–¥–∞–π –ø–æ–ª–Ω—É—é production-ready –∏–Ω—Ñ—Ä–∞—Å—Ç—Ä—É–∫—Ç—É—Ä—É –¥–ª—è –º–∏–∫—Ä–æ—Å–µ—Ä–≤–∏—Å–Ω–æ–π –ø–ª–∞—Ç—Ñ–æ—Ä–º—ã ALGORITHMIC ARTS.
Python 3.12, Node.js 22, Docker 24+, Docker Compose 2.24+.

‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
–ß–ê–°–¢–¨ 1: –°–¢–†–£–ö–¢–£–†–ê –ü–†–û–ï–ö–¢–ê
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

–°–æ–∑–¥–∞–π —Å–ª–µ–¥—É—é—â—É—é —Ñ–∞–π–ª–æ–≤—É—é —Å—Ç—Ä—É–∫—Ç—É—Ä—É (–≤—Å–µ —Ñ–∞–π–ª—ã –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å –∑–∞–ø–æ–ª–Ω–µ–Ω—ã):

platform/
‚îú‚îÄ‚îÄ .env.example                     # –í—Å–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è —Å –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏—è–º–∏
‚îú‚îÄ‚îÄ .gitignore
‚îú‚îÄ‚îÄ .dockerignore
‚îú‚îÄ‚îÄ Makefile                         # –ü–æ–ª–Ω—ã–π –Ω–∞–±–æ—Ä –∫–æ–º–∞–Ω–¥
‚îú‚îÄ‚îÄ docker-compose.yml               # Production-–∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è
‚îú‚îÄ‚îÄ docker-compose.override.yml      # Dev-overrides (volume mounts, hot reload)
‚îú‚îÄ‚îÄ docker-compose.test.yml          # CI/CD –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è
‚îÇ
‚îú‚îÄ‚îÄ services/
‚îÇ   ‚îú‚îÄ‚îÄ api-gateway/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ Dockerfile
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ pyproject.toml
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ src/main.py
‚îÇ   ‚îú‚îÄ‚îÄ auth-service/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ Dockerfile
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ pyproject.toml
‚îÇ   ‚îú‚îÄ‚îÄ user-service/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ Dockerfile
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ pyproject.toml
‚îÇ   ‚îú‚îÄ‚îÄ company-service/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ Dockerfile
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ pyproject.toml
‚îÇ   ‚îú‚îÄ‚îÄ partner-service/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ Dockerfile
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ pyproject.toml
‚îÇ   ‚îú‚îÄ‚îÄ ai-core-service/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ Dockerfile
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ pyproject.toml
‚îÇ   ‚îú‚îÄ‚îÄ data-pipeline/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ Dockerfile
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ pyproject.toml
‚îÇ   ‚îú‚îÄ‚îÄ crm-hub/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ Dockerfile
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ pyproject.toml
‚îÇ   ‚îú‚îÄ‚îÄ search-service/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ Dockerfile
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ pyproject.toml
‚îÇ   ‚îú‚îÄ‚îÄ reporting/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ Dockerfile
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ pyproject.toml
‚îÇ   ‚îú‚îÄ‚îÄ billing/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ Dockerfile
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ pyproject.toml
‚îÇ   ‚îî‚îÄ‚îÄ notification/
‚îÇ       ‚îú‚îÄ‚îÄ Dockerfile
‚îÇ       ‚îî‚îÄ‚îÄ pyproject.toml
‚îÇ
‚îú‚îÄ‚îÄ frontend/
‚îÇ   ‚îú‚îÄ‚îÄ Dockerfile
‚îÇ   ‚îú‚îÄ‚îÄ package.json
‚îÇ   ‚îî‚îÄ‚îÄ .env.local.example
‚îÇ
‚îú‚îÄ‚îÄ shared/                          # –û–±—â–∏–π –∫–æ–¥ –¥–ª—è –≤—Å–µ—Ö —Å–µ—Ä–≤–∏—Å–æ–≤
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ events.py                    # Kafka producer/consumer base
‚îÇ   ‚îú‚îÄ‚îÄ exceptions.py                # –ë–∞–∑–æ–≤—ã–µ –∏—Å–∫–ª—é—á–µ–Ω–∏—è
‚îÇ   ‚îú‚îÄ‚îÄ logging.py                   # Structlog –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è
‚îÇ   ‚îî‚îÄ‚îÄ schemas.py                   # –û–±—â–∏–µ Pydantic-—Å—Ö–µ–º—ã
‚îÇ
‚îú‚îÄ‚îÄ infra/
‚îÇ   ‚îú‚îÄ‚îÄ postgres/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ init.sql                 # –†–∞—Å—à–∏—Ä–µ–Ω–∏—è + –±–∞–∑–æ–≤—ã–µ —Å—Ö–µ–º—ã
‚îÇ   ‚îú‚îÄ‚îÄ monitoring/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ prometheus.yml
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ loki-config.yml
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ grafana/
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ dashboards/
‚îÇ   ‚îÇ       ‚îÇ   ‚îî‚îÄ‚îÄ overview.json
‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ datasources/
‚îÇ   ‚îÇ           ‚îî‚îÄ‚îÄ datasources.yml
‚îÇ   ‚îî‚îÄ‚îÄ kafka/
‚îÇ       ‚îî‚îÄ‚îÄ topics.sh                # –°–æ–∑–¥–∞–Ω–∏–µ —Ç–æ–ø–∏–∫–æ–≤ –ø—Ä–∏ —Å—Ç–∞—Ä—Ç–µ
‚îÇ
‚îú‚îÄ‚îÄ scripts/
‚îÇ   ‚îú‚îÄ‚îÄ generate_secrets.py          # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è JWT-–∫–ª—é—á–µ–π, –ø–∞—Ä–æ–ª–µ–π
‚îÇ   ‚îú‚îÄ‚îÄ check_dependencies.sh        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –≤–µ—Ä—Å–∏–π –ü–û
‚îÇ   ‚îú‚îÄ‚îÄ init_project.sh              # –ü–µ—Ä–≤–∏—á–Ω–∞—è –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è
‚îÇ   ‚îú‚îÄ‚îÄ create_admin.py              # –°–æ–∑–¥–∞–Ω–∏–µ –ø–µ—Ä–≤–æ–≥–æ –∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–æ—Ä–∞
‚îÇ   ‚îî‚îÄ‚îÄ seed_data.py                 # –ó–∞–≥—Ä—É–∑–∫–∞ —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö
‚îÇ
‚îú‚îÄ‚îÄ ai-agents/
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ base_agent.py
‚îÇ   ‚îî‚îÄ‚îÄ orchestrator.py
‚îÇ
‚îî‚îÄ‚îÄ tests/
    ‚îú‚îÄ‚îÄ conftest.py
    ‚îú‚îÄ‚îÄ e2e/
    ‚îî‚îÄ‚îÄ load/
        ‚îî‚îÄ‚îÄ api_load_test.js


‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
–ß–ê–°–¢–¨ 2: –°–ï–†–í–ò–°–´ –ò –ü–û–†–¢–´
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

–°–µ—Ä–≤–∏—Å              | –ü–æ—Ä—Ç  | –¢–µ—Ö–Ω–æ–ª–æ–≥–∏—è
--------------------|-------|---------------------------
api-gateway         |  80   | FastAPI, Caddy
auth-service        | 8001  | FastAPI
user-service        | 8002  | FastAPI
company-service     | 8003  | FastAPI
partner-service     | 8004  | FastAPI
ai-core-service     | 8005  | FastAPI, LangChain
data-pipeline       | 8006  | FastAPI, Scrapy, Celery
crm-hub             | 8007  | FastAPI
search-service      | 8008  | FastAPI, Elasticsearch
reporting           | 8009  | FastAPI, WeasyPrint
billing             | 8010  | FastAPI
notification        | 8011  | FastAPI, Celery
frontend            | 3000  | Next.js 15
postgres            | 5432  | PostgreSQL 17 + pgvector
redis               | 6379  | Redis Stack 7.4
redis-insight       | 8001  | RedisInsight UI
elasticsearch       | 9200  | Elasticsearch 8.14
kafka               | 9092  | Apache Kafka 3.7
zookeeper           | 2181  | ZooKeeper
minio               | 9000  | MinIO (S3)
minio-console       | 9001  | MinIO Console
clickhouse-http     | 8123  | ClickHouse HTTP API
clickhouse-native   | 9000  | ClickHouse Native
prometheus          | 9090  | Prometheus
grafana             | 3001  | Grafana
loki                | 3100  | Loki
jaeger              | 16686 | Jaeger UI
pgadmin             | 5050  | pgAdmin 4


‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
–ß–ê–°–¢–¨ 3: DOCKERFILE (Python-—Å–µ—Ä–≤–∏—Å, multi-stage)
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

–°–æ–∑–¥–∞–π –µ–¥–∏–Ω—ã–π —à–∞–±–ª–æ–Ω Dockerfile –¥–ª—è –≤—Å–µ—Ö Python-—Å–µ—Ä–≤–∏—Å–æ–≤:

# ‚îÄ‚îÄ‚îÄ Stage 1: Builder ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
FROM python:3.12-slim AS builder

RUN pip install poetry==1.8.3

WORKDIR /app

COPY pyproject.toml poetry.lock* ./
RUN poetry config virtualenvs.in-project true && \
    poetry install --only=main --no-interaction --no-ansi

# ‚îÄ‚îÄ‚îÄ Stage 2: Development ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
FROM python:3.12-slim AS development

WORKDIR /app
COPY --from=builder /app/.venv /app/.venv

ENV PATH="/app/.venv/bin:$PATH"
ENV PYTHONPATH=/app
ENV PYTHONDONTWRITEBYTECODE=1
ENV PYTHONUNBUFFERED=1

COPY . .

EXPOSE 8000
CMD ["uvicorn", "src.main:app", "--host", "0.0.0.0", "--port", "8000", "--reload"]

# ‚îÄ‚îÄ‚îÄ Stage 3: Production ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
FROM python:3.12-slim AS production

RUN apt-get update && apt-get install -y --no-install-recommends \
    curl \
    && rm -rf /var/lib/apt/lists/*

# –°–æ–∑–¥–∞—ë–º –Ω–µ–ø—Ä–∏–≤–∏–ª–µ–≥–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
RUN groupadd --gid 1000 appuser && \
    useradd --uid 1000 --gid appuser --shell /bin/bash --create-home appuser

WORKDIR /app
COPY --from=builder /app/.venv /app/.venv
COPY --chown=appuser:appuser . .

USER appuser

ENV PATH="/app/.venv/bin:$PATH"
ENV PYTHONDONTWRITEBYTECODE=1
ENV PYTHONUNBUFFERED=1

# Healthcheck
HEALTHCHECK --interval=30s --timeout=5s --start-period=30s --retries=3 \
    CMD curl -f http://localhost:8000/health || exit 1

EXPOSE 8000
CMD ["uvicorn", "src.main:app", "--host", "0.0.0.0", "--port", "8000", \
     "--workers", "4", "--no-access-log"]


–î–ª—è frontend (Next.js 15):

# ‚îÄ‚îÄ‚îÄ Stage 1: Dependencies ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
FROM node:22-alpine AS deps
WORKDIR /app
COPY package.json package-lock.json* ./
RUN npm ci --only=production

# ‚îÄ‚îÄ‚îÄ Stage 2: Builder ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
FROM node:22-alpine AS builder
WORKDIR /app
COPY --from=deps /app/node_modules ./node_modules
COPY . .
ENV NEXT_TELEMETRY_DISABLED=1
RUN npm run build

# ‚îÄ‚îÄ‚îÄ Stage 3: Production ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
FROM node:22-alpine AS production
WORKDIR /app
ENV NODE_ENV=production
ENV NEXT_TELEMETRY_DISABLED=1

RUN addgroup --system --gid 1001 nodejs && \
    adduser  --system --uid 1001 nextjs

COPY --from=builder /app/public ./public
COPY --from=builder --chown=nextjs:nodejs /app/.next/standalone ./
COPY --from=builder --chown=nextjs:nodejs /app/.next/static ./.next/static

USER nextjs
EXPOSE 3000
CMD ["node", "server.js"]


‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
–ß–ê–°–¢–¨ 4: .env.example (–ø–æ–ª–Ω—ã–π)
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

–°–æ–∑–¥–∞–π .env.example —Å —Ç–∞–∫–∏–º–∏ —Å–µ–∫—Ü–∏—è–º–∏ –∏ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–º–∏:

# ‚îÄ‚îÄ‚îÄ APPLICATION ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
APP_ENV=development              # development | staging | production
APP_DEBUG=true
LOG_LEVEL=INFO                   # DEBUG | INFO | WARNING | ERROR
SECRET_KEY=REPLACE_ME            # 64-byte hex

# ‚îÄ‚îÄ‚îÄ POSTGRESQL ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
DB_HOST=postgres
DB_PORT=5432
DB_USER=algo_user
DB_PASSWORD=REPLACE_ME
DB_NAME=algorithmic_arts
DB_POOL_SIZE=20
DB_MAX_OVERFLOW=40
DATABASE_URL=postgresql+asyncpg://${DB_USER}:${DB_PASSWORD}@${DB_HOST}:${DB_PORT}/${DB_NAME}

# ‚îÄ‚îÄ‚îÄ REDIS ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
REDIS_HOST=redis
REDIS_PORT=6379
REDIS_URL=redis://${REDIS_HOST}:${REDIS_PORT}/0
REDIS_CACHE_TTL=3600             # –°–µ–∫—É–Ω–¥—ã
REDIS_SESSION_TTL=86400

# ‚îÄ‚îÄ‚îÄ ELASTICSEARCH ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
ELASTICSEARCH_URL=http://elasticsearch:9200
ELASTICSEARCH_INDEX_PREFIX=algo

# ‚îÄ‚îÄ‚îÄ KAFKA ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
KAFKA_BOOTSTRAP_SERVERS=kafka:9092
KAFKA_CONSUMER_GROUP_ID=algo-platform
KAFKA_AUTO_OFFSET_RESET=earliest
KAFKA_MAX_POLL_RECORDS=500

# ‚îÄ‚îÄ‚îÄ MINIO ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
MINIO_ENDPOINT=minio:9000
MINIO_ROOT_USER=minioadmin
MINIO_ROOT_PASSWORD=REPLACE_ME
MINIO_BUCKET_UPLOADS=uploads
MINIO_BUCKET_REPORTS=reports
MINIO_BUCKET_BACKUPS=backups

# ‚îÄ‚îÄ‚îÄ CLICKHOUSE ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
CLICKHOUSE_HOST=clickhouse
CLICKHOUSE_PORT=8123
CLICKHOUSE_USER=algo_user
CLICKHOUSE_PASSWORD=REPLACE_ME
CLICKHOUSE_DB=analytics

# ‚îÄ‚îÄ‚îÄ JWT ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
JWT_ALGORITHM=RS256
JWT_ACCESS_TOKEN_EXPIRE_MINUTES=15
JWT_REFRESH_TOKEN_EXPIRE_DAYS=30
# –ì–µ–Ω–µ—Ä–∏—Ä—É—é—Ç—Å—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ —Å–∫—Ä–∏–ø—Ç–æ–º generate_secrets.py:
# JWT_PRIVATE_KEY=...
# JWT_PUBLIC_KEY=...

# ‚îÄ‚îÄ‚îÄ YANDEXGPT ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
YANDEXGPT_API_KEY=REPLACE_ME
YANDEXGPT_FOLDER_ID=REPLACE_ME
YANDEXGPT_MODEL=yandexgpt-pro
YANDEXGPT_TEMPERATURE=0.3
YANDEXGPT_MAX_TOKENS=4000

# ‚îÄ‚îÄ‚îÄ GIGACHAT ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
GIGACHAT_API_KEY=REPLACE_ME
GIGACHAT_SCOPE=GIGACHAT_API_CORP
GIGACHAT_MODEL=GigaChat-Pro

# ‚îÄ‚îÄ‚îÄ OPENROUTER (fallback) ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
OPENROUTER_API_KEY=REPLACE_ME
OPENROUTER_MODEL=anthropic/claude-sonnet-4-5

# ‚îÄ‚îÄ‚îÄ CRM: amoCRM ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
AMOCRM_CLIENT_ID=REPLACE_ME
AMOCRM_CLIENT_SECRET=REPLACE_ME
AMOCRM_REDIRECT_URI=http://localhost/api/v1/crm/amocrm/callback

# ‚îÄ‚îÄ‚îÄ CRM: –ë–∏—Ç—Ä–∏–∫—Å24 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
BITRIX24_CLIENT_ID=REPLACE_ME
BITRIX24_CLIENT_SECRET=REPLACE_ME
BITRIX24_REDIRECT_URI=http://localhost/api/v1/crm/bitrix/callback

# ‚îÄ‚îÄ‚îÄ EMAIL (SMTP) ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
SMTP_HOST=smtp.yandex.ru
SMTP_PORT=587
SMTP_USER=noreply@algorithmic-arts.ru
SMTP_PASSWORD=REPLACE_ME
SMTP_FROM_NAME=ALGORITHMIC ARTS

# ‚îÄ‚îÄ‚îÄ TELEGRAM ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
TELEGRAM_BOT_TOKEN=REPLACE_ME
TELEGRAM_WEBHOOK_URL=https://api.algorithmic-arts.ru/webhooks/telegram

# ‚îÄ‚îÄ‚îÄ PAYMENTS: –ÆKassa ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
YUKASSA_SHOP_ID=REPLACE_ME
YUKASSA_SECRET_KEY=REPLACE_ME
YUKASSA_RETURN_URL=https://algorithmic-arts.ru/billing/success

# ‚îÄ‚îÄ‚îÄ MONITORING ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
GRAFANA_PASSWORD=REPLACE_ME
PGADMIN_EMAIL=admin@algorithmic-arts.ru
PGADMIN_PASSWORD=REPLACE_ME

# ‚îÄ‚îÄ‚îÄ FRONTEND ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
NEXT_PUBLIC_API_URL=http://localhost/api/v1
NEXT_PUBLIC_WS_URL=ws://localhost/ws
NEXT_PUBLIC_APP_NAME=ALGORITHMIC ARTS
NEXT_PUBLIC_SENTRY_DSN=


‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
–ß–ê–°–¢–¨ 5: MAKEFILE (—Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π)
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

.PHONY: help setup start stop restart logs test clean migrate lint build

# ‚îÄ‚îÄ‚îÄ –£—Ç–∏–ª–∏—Ç—ã ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
help:  ## –ü–æ–∫–∞–∑–∞—Ç—å —Å–ø–∏—Å–æ–∫ –∫–æ–º–∞–Ω–¥
	@awk 'BEGIN {FS = ":.*?## "} /^[a-zA-Z_-]+:.*?## / \
	    {printf "\033[36m%-20s\033[0m %s\n", $$1, $$2}' $(MAKEFILE_LIST)

# ‚îÄ‚îÄ‚îÄ –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ø—Ä–æ–µ–∫—Ç–∞ ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
setup: ## –ü–µ—Ä–≤–∏—á–Ω–∞—è –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ø—Ä–æ–µ–∫—Ç–∞
	@echo "üöÄ –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è ALGORITHMIC ARTS..."
	cp -n .env.example .env || true
	python scripts/generate_secrets.py >> .env
	cp -n frontend/.env.local.example frontend/.env.local || true
	@echo "‚úÖ –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞. –û—Ç—Ä–µ–¥–∞–∫—Ç–∏—Ä—É–π—Ç–µ .env –ø–µ—Ä–µ–¥ –∑–∞–ø—É—Å–∫–æ–º."

# ‚îÄ‚îÄ‚îÄ Docker ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
build: ## –ü–µ—Ä–µ—Å–æ–±—Ä–∞—Ç—å Docker-–æ–±—Ä–∞–∑—ã
	docker compose build --no-cache

start: ## –ó–∞–ø—É—Å—Ç–∏—Ç—å –≤—Å–µ —Å–µ—Ä–≤–∏—Å—ã
	docker compose up -d
	@echo "‚è≥ –û–∂–∏–¥–∞–Ω–∏–µ –≥–æ—Ç–æ–≤–Ω–æ—Å—Ç–∏... (30 —Å–µ–∫)"
	sleep 30
	$(MAKE) migrate
	@echo "‚úÖ –ü–ª–∞—Ç—Ñ–æ—Ä–º–∞ –∑–∞–ø—É—â–µ–Ω–∞: http://localhost:3000"

start-infra: ## –ó–∞–ø—É—Å—Ç–∏—Ç—å —Ç–æ–ª—å–∫–æ –∏–Ω—Ñ—Ä–∞—Å—Ç—Ä—É–∫—Ç—É—Ä—É (–ë–î, Kafka, Redis)
	docker compose up -d postgres redis elasticsearch kafka zookeeper minio clickhouse

stop: ## –û—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –≤—Å–µ —Å–µ—Ä–≤–∏—Å—ã
	docker compose down

restart: ## –ü–µ—Ä–µ–∑–∞–ø—É—Å—Ç–∏—Ç—å –≤—Å–µ —Å–µ—Ä–≤–∏—Å—ã
	docker compose restart

restart-svc: ## –ü–µ—Ä–µ–∑–∞–ø—É—Å—Ç–∏—Ç—å –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–π —Å–µ—Ä–≤–∏—Å: make restart-svc SVC=company-service
	docker compose restart $(SVC)

logs: ## –õ–æ–≥–∏ –≤—Å–µ—Ö —Å–µ—Ä–≤–∏—Å–æ–≤ (—Å–ª–µ–¥–∏—Ç—å)
	docker compose logs -f

logs-svc: ## –õ–æ–≥–∏ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ —Å–µ—Ä–≤–∏—Å–∞: make logs-svc SVC=auth-service
	docker compose logs -f $(SVC)

ps: ## –°—Ç–∞—Ç—É—Å –≤—Å–µ—Ö –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–æ–≤
	docker compose ps

# ‚îÄ‚îÄ‚îÄ –ú–∏–≥—Ä–∞—Ü–∏–∏ ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
migrate: ## –ü—Ä–∏–º–µ–Ω–∏—Ç—å –≤—Å–µ –º–∏–≥—Ä–∞—Ü–∏–∏
	@for svc in auth-service user-service company-service partner-service billing; do \
	    echo "  ‚Üí –ú–∏–≥—Ä–∞—Ü–∏—è $$svc..."; \
	    docker compose exec $$svc alembic upgrade head; \
	done

migrate-svc: ## –ú–∏–≥—Ä–∏—Ä–æ–≤–∞—Ç—å –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–π —Å–µ—Ä–≤–∏—Å: make migrate-svc SVC=company-service
	docker compose exec $(SVC) alembic upgrade head

rollback: ## –û—Ç–∫–∞—Ç–∏—Ç—å –ø–æ—Å–ª–µ–¥–Ω—é—é –º–∏–≥—Ä–∞—Ü–∏—é: make rollback SVC=company-service
	docker compose exec $(SVC) alembic downgrade -1

migration-new: ## –°–æ–∑–¥–∞—Ç—å –Ω–æ–≤—É—é –º–∏–≥—Ä–∞—Ü–∏—é: make migration-new SVC=company-service MSG="add_index"
	docker compose exec $(SVC) alembic revision --autogenerate -m "$(MSG)"

# ‚îÄ‚îÄ‚îÄ –¢–µ—Å—Ç—ã ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
test: ## –ó–∞–ø—É—Å—Ç–∏—Ç—å –≤—Å–µ —Ç–µ—Å—Ç—ã
	@for svc in auth-service user-service company-service partner-service; do \
	    echo "  ‚Üí –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ $$svc..."; \
	    docker compose exec $$svc poetry run pytest tests/ -v --cov=src --cov-report=term-missing; \
	done
	cd frontend && npm test

test-svc: ## –¢–µ—Å—Ç–∏—Ä–æ–≤–∞—Ç—å –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–π —Å–µ—Ä–≤–∏—Å: make test-svc SVC=auth-service
	docker compose exec $(SVC) poetry run pytest tests/ -v --cov=src

test-coverage: ## –û—Ç—á—ë—Ç –æ –ø–æ–∫—Ä—ã—Ç–∏–∏ (HTML): make test-coverage SVC=company-service
	docker compose exec $(SVC) poetry run pytest --cov=src --cov-report=html
	@echo "–û—Ç–∫—Ä–æ–π—Ç–µ: services/$(SVC)/htmlcov/index.html"

test-load: ## –ù–∞–≥—Ä—É–∑–æ—á–Ω–æ–µ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ
	k6 run tests/load/api_load_test.js

# ‚îÄ‚îÄ‚îÄ Shell –¥–æ—Å—Ç—É–ø ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
shell-db: ## PostgreSQL shell
	docker compose exec postgres psql -U algo_user -d algorithmic_arts

shell-redis: ## Redis CLI
	docker compose exec redis redis-cli

shell-svc: ## Shell —Å–µ—Ä–≤–∏—Å–∞: make shell-svc SVC=company-service
	docker compose exec $(SVC) bash

# ‚îÄ‚îÄ‚îÄ –î–∞–Ω–Ω—ã–µ ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
seed: ## –ó–∞–≥—Ä—É–∑–∏—Ç—å —Ç–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ (100 –∫–æ–º–ø–∞–Ω–∏–π)
	docker compose exec data-pipeline python scripts/seed_data.py --count=100

create-admin: ## –°–æ–∑–¥–∞—Ç—å –ø–µ—Ä–≤–æ–≥–æ –∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–æ—Ä–∞
	docker compose exec api-gateway python scripts/create_admin.py

# ‚îÄ‚îÄ‚îÄ –õ–∏–Ω—Ç–∏–Ω–≥ ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
lint: ## –ü—Ä–æ–≤–µ—Ä–∏—Ç—å —Å—Ç–∏–ª—å –∫–æ–¥–∞
	@for svc in auth-service user-service company-service partner-service; do \
	    docker compose exec $$svc poetry run ruff check src/ tests/; \
	    docker compose exec $$svc poetry run mypy src/; \
	done
	cd frontend && npm run lint

format: ## –û—Ç—Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞—Ç—å –∫–æ–¥
	@for svc in auth-service user-service company-service partner-service; do \
	    docker compose exec $$svc poetry run ruff format src/ tests/; \
	done

# ‚îÄ‚îÄ‚îÄ –û—á–∏—Å—Ç–∫–∞ ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
clean: ## –û—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –∏ —É–¥–∞–ª–∏—Ç—å –≤—Å–µ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä—ã –∏ —Ç–æ–º–∞
	docker compose down -v --remove-orphans
	docker system prune -f

clean-images: ## –£–¥–∞–ª–∏—Ç—å —Å–æ–±—Ä–∞–Ω–Ω—ã–µ –æ–±—Ä–∞–∑—ã
	docker compose down --rmi local


‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
–ß–ê–°–¢–¨ 6: –°–ö–†–ò–ü–¢–´
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

## scripts/generate_secrets.py:

#!/usr/bin/env python3
"""–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∫—Ä–∏–ø—Ç–æ–≥—Ä–∞—Ñ–∏—á–µ—Å–∫–∏ —Å—Ç–æ–π–∫–∏—Ö —Å–µ–∫—Ä–µ—Ç–æ–≤ –¥–ª—è .env"""

import secrets
import base64
from cryptography.hazmat.primitives import serialization
from cryptography.hazmat.primitives.asymmetric import rsa
from cryptography.hazmat.backends import default_backend


def generate_rsa_key_pair():
    """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –ø–∞—Ä—É RSA-–∫–ª—é—á–µ–π –¥–ª—è RS256 JWT."""
    private_key = rsa.generate_private_key(
        public_exponent=65537,
        key_size=2048,
        backend=default_backend()
    )
    private_pem = private_key.private_bytes(
        encoding=serialization.Encoding.PEM,
        format=serialization.PrivateFormat.TraditionalOpenSSL,
        encryption_algorithm=serialization.NoEncryption()
    ).decode()

    public_pem = private_key.public_key().public_bytes(
        encoding=serialization.Encoding.PEM,
        format=serialization.PublicFormat.SubjectPublicKeyInfo
    ).decode()

    return private_pem, public_pem


def main():
    # –°–ª—É—á–∞–π–Ω—ã–µ –ø–∞—Ä–æ–ª–∏ –¥–ª—è –ë–î
    print(f"DB_PASSWORD={secrets.token_urlsafe(32)}")
    print(f"CLICKHOUSE_PASSWORD={secrets.token_urlsafe(32)}")
    print(f"MINIO_ROOT_PASSWORD={secrets.token_urlsafe(32)}")
    print(f"SECRET_KEY={secrets.token_hex(64)}")
    print(f"GRAFANA_PASSWORD={secrets.token_urlsafe(16)}")
    print(f"PGADMIN_PASSWORD={secrets.token_urlsafe(16)}")

    # RSA –∫–ª—é—á–∏ –¥–ª—è JWT
    private_pem, public_pem = generate_rsa_key_pair()
    # –ö–æ–¥–∏—Ä—É–µ–º –≤ base64 –¥–ª—è —É–¥–æ–±—Å—Ç–≤–∞ —Ö—Ä–∞–Ω–µ–Ω–∏—è –≤ .env
    private_b64 = base64.b64encode(private_pem.encode()).decode()
    public_b64  = base64.b64encode(public_pem.encode()).decode()
    print(f"JWT_PRIVATE_KEY={private_b64}")
    print(f"JWT_PUBLIC_KEY={public_b64}")

if __name__ == "__main__":
    main()


## scripts/check_dependencies.sh:

#!/bin/bash
set -e
ERRORS=0

check_version() {
    local tool=$1
    local required=$2
    local actual=$($3 2>/dev/null | head -1 | grep -oE '[0-9]+\.[0-9]+')

    if [ -z "$actual" ]; then
        echo "‚ùå $tool –Ω–µ –Ω–∞–π–¥–µ–Ω"
        ERRORS=$((ERRORS+1))
    else
        echo "‚úÖ $tool $actual (—Ç—Ä–µ–±—É–µ—Ç—Å—è >= $required)"
    fi
}

echo "üîç –ü—Ä–æ–≤–µ—Ä–∫–∞ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π ALGORITHMIC ARTS..."
check_version "Docker"         "24.0" "docker --version"
check_version "Docker Compose" "2.24" "docker compose version"
check_version "Python"         "3.12" "python3 --version"
check_version "Node.js"        "22.0" "node --version"
check_version "Git"            "2.40" "git --version"

[ $ERRORS -eq 0 ] && echo "‚úÖ –í—Å–µ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –≤ –ø–æ—Ä—è–¥–∫–µ!" \
                  || echo "‚ùå –ù–∞–π–¥–µ–Ω–æ –æ—à–∏–±–æ–∫: $ERRORS. –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ –Ω–µ–¥–æ—Å—Ç–∞—é—â–∏–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã."
exit $ERRORS


## infra/postgres/init.sql:

-- –†–∞—Å—à–∏—Ä–µ–Ω–∏—è PostgreSQL 17
CREATE EXTENSION IF NOT EXISTS "uuid-ossp";
CREATE EXTENSION IF NOT EXISTS "pgvector";
CREATE EXTENSION IF NOT EXISTS "pg_cron";
CREATE EXTENSION IF NOT EXISTS "pg_stat_statements";

-- Citus (—à–∞—Ä–¥–∏—Ä–æ–≤–∞–Ω–∏–µ ‚Äî —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –≤–∫–ª—é—á—ë–Ω)
-- CREATE EXTENSION IF NOT EXISTS "citus";

-- Shared —Ç—Ä–∏–≥–≥–µ—Ä –¥–ª—è auto-update updated_at
CREATE OR REPLACE FUNCTION set_updated_at()
RETURNS TRIGGER AS $$
BEGIN
    NEW.updated_at = NOW();
    RETURN NEW;
END;
$$ LANGUAGE plpgsql;

-- –ú–∞–∫—Ä–æ—Å –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è —Ç—Ä–∏–≥–≥–µ—Ä–∞ –Ω–∞ —Ç–∞–±–ª–∏—Ü—É
-- –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ: SELECT create_updated_at_trigger('companies');
CREATE OR REPLACE FUNCTION create_updated_at_trigger(table_name TEXT)
RETURNS void AS $$
BEGIN
    EXECUTE format(
        'CREATE TRIGGER set_updated_at
         BEFORE UPDATE ON %I
         FOR EACH ROW EXECUTE FUNCTION set_updated_at()',
        table_name
    );
END;
$$ LANGUAGE plpgsql;


## infra/kafka/topics.sh:

#!/bin/bash
# –°–æ–∑–¥–∞–Ω–∏–µ –≤—Å–µ—Ö Kafka —Ç–æ–ø–∏–∫–æ–≤ –ø—Ä–∏ –ø–µ—Ä–≤–æ–º –∑–∞–ø—É—Å–∫–µ
KAFKA="kafka:9092"
PARTITIONS=3
REPLICATION=1

create_topic() {
    kafka-topics.sh --create \
        --bootstrap-server $KAFKA \
        --topic $1 \
        --partitions $PARTITIONS \
        --replication-factor $REPLICATION \
        --if-not-exists
}

echo "üîß –°–æ–∑–¥–∞–Ω–∏–µ Kafka —Ç–æ–ø–∏–∫–æ–≤..."

# Company domain
create_topic "company.created"
create_topic "company.updated"
create_topic "company.enriched"
create_topic "company.deleted"

# Partnership domain
create_topic "partnership.matched"
create_topic "partnership.status_changed"
create_topic "partnership.deal_closed"

# User domain
create_topic "user.created"
create_topic "user.updated"
create_topic "user.login_failed"

# Billing domain
create_topic "billing.subscription_created"
create_topic "billing.subscription_changed"
create_topic "billing.payment_succeeded"
create_topic "billing.payment_failed"

# AI domain
create_topic "ai.analysis.queue"
create_topic "ai.analysis.results"

# CRM / Notifications
create_topic "crm.sync.requested"
create_topic "notification.events"

echo "‚úÖ –¢–æ–ø–∏–∫–∏ —Å–æ–∑–¥–∞–Ω—ã"

–û–ë–©–ò–ï –¢–†–ï–ë–û–í–ê–ù–ò–Ø:
- docker-compose.yml: healthcheck –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —Å–µ—Ä–≤–∏—Å–∞, depends_on —Å condition
- docker-compose.override.yml: volume-–º–∞—É–Ω—Ç—ã –¥–ª—è hot reload –≤ dev-—Ä–µ–∂–∏–º–µ
- shared/logging.py: structlog —Å JSON-—Ñ–æ—Ä–º–∞—Ç–æ–º, request_id –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ
- shared/events.py: –±–∞–∑–æ–≤—ã–π KafkaProducer –∏ KafkaConsumer —Å retry-–ª–æ–≥–∏–∫–æ–π
- –í—Å–µ —Å–µ–∫—Ä–µ—Ç—ã ‚Äî —Ç–æ–ª—å–∫–æ —á–µ—Ä–µ–∑ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è, –Ω–µ —Ö–∞—Ä–¥–∫–æ–¥–∏—Ç—å

–°–æ–∑–¥–∞–π –≤—Å–µ —Ñ–∞–π–ª—ã, –≤–∫–ª—é—á–∞—è –∑–∞–≥–ª—É—à–∫–∏ src/main.py –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —Å–µ—Ä–≤–∏—Å–∞ —Å /health –∏ /metrics.
```

---

## –ü—Ä–æ–º–ø—Ç ‚Ññ2: –ë–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö (–†–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π)

### –ó–∞–¥–∞—á–∞
–°–æ–∑–¥–∞—Ç—å –≤—Å–µ —Å—Ö–µ–º—ã PostgreSQL, Alembic-–º–∏–≥—Ä–∞—Ü–∏–∏, SQLAlchemy 2.0 –º–æ–¥–µ–ª–∏, ClickHouse-—Å—Ö–µ–º—É –∏ seed-—Å–∫—Ä–∏–ø—Ç.

### –ü—Ä–æ–º–ø—Ç

```markdown
–°–æ–∑–¥–∞–π –ø–æ–ª–Ω—ã–µ —Å—Ö–µ–º—ã –±–∞–∑ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –ø–ª–∞—Ç—Ñ–æ—Ä–º—ã ALGORITHMIC ARTS.
PostgreSQL 17, pgvector 0.7+, SQLAlchemy 2.0 (async + Mapped), Alembic 1.14.

‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
–ß–ê–°–¢–¨ 1: SQL DDL ‚Äî AUTH DATABASE
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

-- Enum —Ç–∏–ø—ã
CREATE TYPE user_role AS ENUM ('free_user', 'paid_user', 'company_admin', 'platform_admin');
CREATE TYPE oauth_provider AS ENUM ('yandex', 'google', 'vk');

-- –¢–∞–±–ª–∏—Ü–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π
CREATE TABLE users (
    id                  UUID            PRIMARY KEY DEFAULT gen_random_uuid(),
    email               VARCHAR(255)    NOT NULL UNIQUE,
    password_hash       VARCHAR(72)     NOT NULL,           -- bcrypt, cost 12
    full_name           VARCHAR(255)    NOT NULL,
    company_name        VARCHAR(255),
    role                user_role       NOT NULL DEFAULT 'free_user',
    is_active           BOOLEAN         NOT NULL DEFAULT FALSE,
    is_verified         BOOLEAN         NOT NULL DEFAULT FALSE,
    totp_secret         VARCHAR(32),                        -- NULL = 2FA –æ—Ç–∫–ª—é—á–µ–Ω–∞
    totp_enabled        BOOLEAN         NOT NULL DEFAULT FALSE,
    last_login_at       TIMESTAMPTZ,
    failed_login_count  INTEGER         NOT NULL DEFAULT 0,
    created_at          TIMESTAMPTZ     NOT NULL DEFAULT NOW(),
    updated_at          TIMESTAMPTZ     NOT NULL DEFAULT NOW(),
    deleted_at          TIMESTAMPTZ
);

-- –ò–Ω–¥–µ–∫—Å—ã users
CREATE INDEX idx_users_email         ON users (email)      WHERE deleted_at IS NULL;
CREATE INDEX idx_users_role          ON users (role)       WHERE deleted_at IS NULL;
CREATE INDEX idx_users_created_at    ON users (created_at DESC);
SELECT create_updated_at_trigger('users');

-- Refresh-—Ç–æ–∫–µ–Ω—ã (—Ö—Ä–∞–Ω—è—Ç—Å—è –∑–∞—à–∏—Ñ—Ä–æ–≤–∞–Ω–Ω—ã–º–∏)
CREATE TABLE refresh_tokens (
    id              UUID        PRIMARY KEY DEFAULT gen_random_uuid(),
    user_id         UUID        NOT NULL REFERENCES users(id) ON DELETE CASCADE,
    token_hash      VARCHAR(64) NOT NULL UNIQUE,            -- SHA-256 –æ—Ç —Ç–æ–∫–µ–Ω–∞
    expires_at      TIMESTAMPTZ NOT NULL,
    created_at      TIMESTAMPTZ NOT NULL DEFAULT NOW(),
    revoked_at      TIMESTAMPTZ
);

CREATE INDEX idx_refresh_tokens_user_id    ON refresh_tokens (user_id);
CREATE INDEX idx_refresh_tokens_expires_at ON refresh_tokens (expires_at)
    WHERE revoked_at IS NULL;

-- OAuth-–ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è
CREATE TABLE oauth_connections (
    id              UUID            PRIMARY KEY DEFAULT gen_random_uuid(),
    user_id         UUID            NOT NULL REFERENCES users(id) ON DELETE CASCADE,
    provider        oauth_provider  NOT NULL,
    external_id     VARCHAR(255)    NOT NULL,
    access_token    TEXT,
    refresh_token   TEXT,
    expires_at      TIMESTAMPTZ,
    created_at      TIMESTAMPTZ     NOT NULL DEFAULT NOW(),
    updated_at      TIMESTAMPTZ     NOT NULL DEFAULT NOW(),
    UNIQUE (provider, external_id)
);

CREATE INDEX idx_oauth_user_id ON oauth_connections (user_id);
SELECT create_updated_at_trigger('oauth_connections');

-- Email –≤–µ—Ä–∏—Ñ–∏–∫–∞—Ü–∏—è / —Å–±—Ä–æ—Å –ø–∞—Ä–æ–ª—è
CREATE TABLE verification_tokens (
    id          UUID        PRIMARY KEY DEFAULT gen_random_uuid(),
    user_id     UUID        NOT NULL REFERENCES users(id) ON DELETE CASCADE,
    token       VARCHAR(64) NOT NULL UNIQUE,                -- –∫—Ä–∏–ø—Ç–æ–≥—Ä–∞—Ñ–∏—á–µ—Å–∫–∏ —Å–ª—É—á–∞–π–Ω—ã–π
    purpose     VARCHAR(32) NOT NULL,                       -- 'email_verify' | 'password_reset'
    expires_at  TIMESTAMPTZ NOT NULL,
    used_at     TIMESTAMPTZ,
    created_at  TIMESTAMPTZ NOT NULL DEFAULT NOW()
);

CREATE INDEX idx_verification_tokens_token   ON verification_tokens (token) WHERE used_at IS NULL;
CREATE INDEX idx_verification_tokens_user_id ON verification_tokens (user_id);

-- pg_cron: –æ—á–∏—Å—Ç–∫–∞ –ø—Ä–æ—Å—Ä–æ—á–µ–Ω–Ω—ã—Ö —Ç–æ–∫–µ–Ω–æ–≤ –∫–∞–∂–¥—ã–π —á–∞—Å
SELECT cron.schedule('cleanup-expired-tokens', '0 * * * *',
    $$DELETE FROM verification_tokens WHERE expires_at < NOW()$$);
SELECT cron.schedule('cleanup-refresh-tokens', '30 * * * *',
    $$DELETE FROM refresh_tokens WHERE expires_at < NOW() AND revoked_at IS NOT NULL$$);


‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
–ß–ê–°–¢–¨ 2: SQL DDL ‚Äî COMPANY DATABASE
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

-- Enum —Ç–∏–ø—ã
CREATE TYPE funding_stage AS ENUM (
    'pre_seed', 'seed', 'series_a', 'series_b', 'series_c',
    'series_d_plus', 'ipo', 'bootstrapped', 'unknown'
);
CREATE TYPE employees_range AS ENUM (
    '1-10', '11-50', '51-200', '201-500', '500+'
);
CREATE TYPE business_model AS ENUM (
    'b2b', 'b2c', 'b2b2c', 'marketplace', 'platform', 'other'
);

-- –û—Å–Ω–æ–≤–Ω–∞—è —Ç–∞–±–ª–∏—Ü–∞ –∫–æ–º–ø–∞–Ω–∏–π
CREATE TABLE companies (
    id                  UUID            PRIMARY KEY DEFAULT gen_random_uuid(),
    name                VARCHAR(255)    NOT NULL,
    slug                VARCHAR(255)    NOT NULL UNIQUE,    -- URL-friendly –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä
    description         TEXT,
    website             VARCHAR(500),
    logo_url            VARCHAR(500),
    industry            VARCHAR(100)    NOT NULL,
    sub_industries      TEXT[]          NOT NULL DEFAULT '{}',
    business_model      business_model,
    founded_year        SMALLINT        CHECK (founded_year BETWEEN 1900 AND 2030),
    headquarters_country VARCHAR(10)    NOT NULL DEFAULT 'RU',
    headquarters_city   VARCHAR(100),
    employees_count     INTEGER         CHECK (employees_count > 0),
    employees_range     employees_range,
    funding_total       BIGINT,                             -- –≤ –∫–æ–ø–µ–π–∫–∞—Ö
    funding_currency    VARCHAR(3)      NOT NULL DEFAULT 'RUB',
    funding_stage       funding_stage   DEFAULT 'unknown',
    last_funding_date   DATE,
    inn                 VARCHAR(12)     UNIQUE,             -- –ò–ù–ù 10 –∏–ª–∏ 12 —Ü–∏—Ñ—Ä
    ogrn                VARCHAR(15)     UNIQUE,             -- –û–ì–†–ù 13 –∏–ª–∏ 15 —Ü–∏—Ñ—Ä
    kpp                 VARCHAR(9),
    legal_name          VARCHAR(500),
    tech_stack          JSONB           NOT NULL DEFAULT '{}',
    integrations        TEXT[]          NOT NULL DEFAULT '{}',
    api_available       BOOLEAN         NOT NULL DEFAULT FALSE,
    ai_summary          TEXT,
    ai_tags             TEXT[]          NOT NULL DEFAULT '{}',
    embedding           VECTOR(768),                        -- paraphrase-multilingual-mpnet
    is_verified         BOOLEAN         NOT NULL DEFAULT FALSE,
    view_count          INTEGER         NOT NULL DEFAULT 0,
    source_url          VARCHAR(500),
    created_at          TIMESTAMPTZ     NOT NULL DEFAULT NOW(),
    updated_at          TIMESTAMPTZ     NOT NULL DEFAULT NOW(),
    deleted_at          TIMESTAMPTZ
);

-- –ò–Ω–¥–µ–∫—Å—ã companies
CREATE INDEX idx_companies_industry     ON companies (industry) WHERE deleted_at IS NULL;
CREATE INDEX idx_companies_country_city ON companies (headquarters_country, headquarters_city)
    WHERE deleted_at IS NULL;
CREATE INDEX idx_companies_funding      ON companies (funding_stage) WHERE deleted_at IS NULL;
CREATE INDEX idx_companies_founded      ON companies (founded_year)  WHERE deleted_at IS NULL;
CREATE INDEX idx_companies_inn          ON companies (inn)           WHERE inn IS NOT NULL;

-- GIN-–∏–Ω–¥–µ–∫—Å—ã –¥–ª—è –º–∞—Å—Å–∏–≤–æ–≤ –∏ JSONB
CREATE INDEX idx_companies_sub_industries ON companies USING GIN (sub_industries);
CREATE INDEX idx_companies_tech_stack     ON companies USING GIN (tech_stack);
CREATE INDEX idx_companies_integrations   ON companies USING GIN (integrations);
CREATE INDEX idx_companies_ai_tags        ON companies USING GIN (ai_tags);

-- IVFFlat-–∏–Ω–¥–µ–∫—Å –¥–ª—è pgvector (cosine distance)
-- –ó–Ω–∞—á–µ–Ω–∏–µ lists: sqrt(–∫–æ–ª-–≤–æ —Å—Ç—Ä–æ–∫). –î–ª—è 5000 —Å—Ç—Ä–æ–∫ ‚âà 70
CREATE INDEX idx_companies_embedding ON companies
    USING ivfflat (embedding vector_cosine_ops) WITH (lists = 100)
    WHERE embedding IS NOT NULL;

SELECT create_updated_at_trigger('companies');

-- –ò—Å—Ç–æ—Ä–∏—è –æ–±–Ω–æ–≤–ª–µ–Ω–∏–π –∫–æ–º–ø–∞–Ω–∏–∏
CREATE TABLE company_updates (
    id          UUID        PRIMARY KEY DEFAULT gen_random_uuid(),
    company_id  UUID        NOT NULL REFERENCES companies(id) ON DELETE CASCADE,
    update_type VARCHAR(50) NOT NULL,   -- 'news' | 'funding' | 'team' | 'product'
    title       VARCHAR(500),
    content     TEXT,
    source_url  VARCHAR(500),
    published_at TIMESTAMPTZ NOT NULL,
    created_at  TIMESTAMPTZ NOT NULL DEFAULT NOW()
) PARTITION BY RANGE (published_at);

-- –°–æ–∑–¥–∞—ë–º –ø–∞—Ä—Ç–∏—Ü–∏–∏ –ø–æ –∫–≤–∞—Ä—Ç–∞–ª–∞–º 2025-2027
CREATE TABLE company_updates_2025_q1 PARTITION OF company_updates
    FOR VALUES FROM ('2025-01-01') TO ('2025-04-01');
CREATE TABLE company_updates_2025_q2 PARTITION OF company_updates
    FOR VALUES FROM ('2025-04-01') TO ('2025-07-01');
CREATE TABLE company_updates_2025_q3 PARTITION OF company_updates
    FOR VALUES FROM ('2025-07-01') TO ('2025-10-01');
CREATE TABLE company_updates_2025_q4 PARTITION OF company_updates
    FOR VALUES FROM ('2025-10-01') TO ('2026-01-01');
CREATE TABLE company_updates_2026_q1 PARTITION OF company_updates
    FOR VALUES FROM ('2026-01-01') TO ('2026-04-01');
CREATE TABLE company_updates_2026_q2 PARTITION OF company_updates
    FOR VALUES FROM ('2026-04-01') TO ('2026-07-01');

CREATE INDEX idx_company_updates_company_id
    ON company_updates (company_id, published_at DESC);

-- –ú–µ—Ç—Ä–∏–∫–∏ –∫–æ–º–ø–∞–Ω–∏–∏
CREATE TABLE company_metrics (
    id              UUID        PRIMARY KEY DEFAULT gen_random_uuid(),
    company_id      UUID        NOT NULL REFERENCES companies(id) ON DELETE CASCADE,
    metric_name     VARCHAR(100) NOT NULL,  -- 'mrr_rub' | 'employees_count' | 'website_visits'
    metric_value    NUMERIC(20,4) NOT NULL,
    measured_at     TIMESTAMPTZ NOT NULL,
    created_at      TIMESTAMPTZ NOT NULL DEFAULT NOW()
) PARTITION BY RANGE (measured_at);

CREATE TABLE company_metrics_2025 PARTITION OF company_metrics
    FOR VALUES FROM ('2025-01-01') TO ('2026-01-01');
CREATE TABLE company_metrics_2026 PARTITION OF company_metrics
    FOR VALUES FROM ('2026-01-01') TO ('2027-01-01');

CREATE INDEX idx_company_metrics_company_metric
    ON company_metrics (company_id, metric_name, measured_at DESC);

-- Event Store –¥–ª—è Company Aggregate (Event Sourcing)
CREATE TABLE company_events (
    id              UUID        PRIMARY KEY DEFAULT gen_random_uuid(),
    company_id      UUID        NOT NULL,
    event_type      VARCHAR(100) NOT NULL,
    event_version   INTEGER     NOT NULL,
    payload         JSONB       NOT NULL,
    occurred_at     TIMESTAMPTZ NOT NULL DEFAULT NOW(),
    UNIQUE (company_id, event_version)
);

CREATE INDEX idx_company_events_company_version
    ON company_events (company_id, event_version ASC);


‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
–ß–ê–°–¢–¨ 3: SQL DDL ‚Äî PARTNERSHIP DATABASE
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

CREATE TYPE partnership_status AS ENUM (
    'suggested',    -- –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –Ω–∞–π–¥–µ–Ω–æ —Å–∏—Å—Ç–µ–º–æ–π
    'reviewed',     -- –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –ø—Ä–æ—Å–º–æ—Ç—Ä–µ–ª
    'interested',   -- –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –∑–∞–∏–Ω—Ç–µ—Ä–µ—Å–æ–≤–∞–Ω
    'contacted',    -- –û—Ç–ø—Ä–∞–≤–ª–µ–Ω–æ outreach –ø–∏—Å—å–º–æ
    'responded',    -- –ü–æ–ª—É—á–µ–Ω –æ—Ç–≤–µ—Ç
    'negotiating',  -- –ò–¥—É—Ç –ø–µ—Ä–µ–≥–æ–≤–æ—Ä—ã
    'active',       -- –ü–∞—Ä—Ç–Ω—ë—Ä—Å—Ç–≤–æ –∑–∞–∫–ª—é—á–µ–Ω–æ
    'closed',       -- –ó–∞–≤–µ—Ä—à–µ–Ω–æ
    'rejected'      -- –û—Ç–∫–ª–æ–Ω–µ–Ω–æ
);

CREATE TYPE analysis_method AS ENUM (
    'auto_vector_scoring',  -- –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π: vector search + scoring
    'user_requested',       -- –ò–Ω–∏—Ü–∏–∏—Ä–æ–≤–∞–Ω–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º
    'ai_deep_analysis'      -- –ì–ª—É–±–æ–∫–∏–π AI-–∞–Ω–∞–ª–∏–∑ (LLM)
);

CREATE TABLE partnerships (
    id                          UUID                PRIMARY KEY DEFAULT gen_random_uuid(),
    company_a_id                UUID                NOT NULL REFERENCES companies(id),
    company_b_id                UUID                NOT NULL REFERENCES companies(id),
    compatibility_score         NUMERIC(5,4)        NOT NULL    -- 0.0000 - 1.0000
                                    CHECK (compatibility_score BETWEEN 0 AND 1),
    tech_compatibility_score    NUMERIC(5,4),
    market_overlap_score        NUMERIC(5,4),
    size_match_score            NUMERIC(5,4),
    geo_proximity_score         NUMERIC(5,4),
    no_competition_score        NUMERIC(5,4),
    complementarity_score       NUMERIC(5,4),
    match_reasons               TEXT[]              NOT NULL DEFAULT '{}',
    synergy_areas               TEXT[]              NOT NULL DEFAULT '{}',
    recommended_type            VARCHAR(50),                    -- 'integration' | 'reseller' | 'co-development'
    analysis_method             analysis_method     NOT NULL DEFAULT 'auto_vector_scoring',
    analyzed_by_agent           VARCHAR(100),
    ai_explanation              TEXT,
    status                      partnership_status  NOT NULL DEFAULT 'suggested',
    viewed_at                   TIMESTAMPTZ,
    contacted_at                TIMESTAMPTZ,
    responded_at                TIMESTAMPTZ,
    partnership_started_at      TIMESTAMPTZ,
    deal_value                  BIGINT,                         -- –≤ –∫–æ–ø–µ–π–∫–∞—Ö
    revenue_generated           BIGINT,                         -- –≤ –∫–æ–ø–µ–π–∫–∞—Ö
    notes                       TEXT,
    created_at                  TIMESTAMPTZ         NOT NULL DEFAULT NOW(),
    updated_at                  TIMESTAMPTZ         NOT NULL DEFAULT NOW(),

    -- –£–Ω–∏–∫–∞–ª—å–Ω–æ—Å—Ç—å: –ø–∞—Ä–∞ –∫–æ–º–ø–∞–Ω–∏–π –≤—Å—Ç—Ä–µ—á–∞–µ—Ç—Å—è –æ–¥–∏–Ω —Ä–∞–∑ (–Ω–µ–∑–∞–≤–∏—Å–∏–º–æ –æ—Ç –ø–æ—Ä—è–¥–∫–∞)
    CONSTRAINT unique_company_pair CHECK (company_a_id < company_b_id),
    UNIQUE (company_a_id, company_b_id)
);

CREATE INDEX idx_partnerships_company_a      ON partnerships (company_a_id, compatibility_score DESC);
CREATE INDEX idx_partnerships_company_b      ON partnerships (company_b_id, compatibility_score DESC);
CREATE INDEX idx_partnerships_status         ON partnerships (status, created_at DESC);
CREATE INDEX idx_partnerships_high_score     ON partnerships (compatibility_score DESC)
    WHERE status = 'suggested';
SELECT create_updated_at_trigger('partnerships');

-- Outreach-—Å–æ–æ–±—â–µ–Ω–∏—è
CREATE TABLE outreach_messages (
    id                  UUID        PRIMARY KEY DEFAULT gen_random_uuid(),
    partnership_id      UUID        NOT NULL REFERENCES partnerships(id) ON DELETE CASCADE,
    sent_by_user_id     UUID        REFERENCES users(id),       -- NULL = –∞–≤—Ç–æ
    channel             VARCHAR(20) NOT NULL DEFAULT 'email',   -- 'email' | 'telegram'
    message_text        TEXT        NOT NULL,
    sent_at             TIMESTAMPTZ,
    delivery_status     VARCHAR(20) DEFAULT 'pending',          -- 'pending' | 'sent' | 'failed'
    response_received   BOOLEAN     NOT NULL DEFAULT FALSE,
    response_text       TEXT,
    responded_at        TIMESTAMPTZ,
    created_at          TIMESTAMPTZ NOT NULL DEFAULT NOW()
);

CREATE INDEX idx_outreach_partnership_id ON outreach_messages (partnership_id, sent_at DESC);


‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
–ß–ê–°–¢–¨ 4: SQL DDL ‚Äî CRM –ò BILLING DATABASES
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

-- CRM-–ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è
CREATE TYPE crm_type AS ENUM ('amocrm', 'bitrix24', 'salesforce', 'hubspot');
CREATE TYPE sync_direction AS ENUM ('to_crm', 'from_crm', 'bidirectional');
CREATE TYPE sync_status AS ENUM ('pending', 'success', 'failed', 'partial');

CREATE TABLE crm_connections (
    id              UUID        PRIMARY KEY DEFAULT gen_random_uuid(),
    user_id         UUID        NOT NULL REFERENCES users(id) ON DELETE CASCADE,
    crm_type        crm_type    NOT NULL,
    access_token    TEXT        NOT NULL,           -- AES-256 –∑–∞—à–∏—Ñ—Ä–æ–≤–∞–Ω
    refresh_token   TEXT,                           -- AES-256 –∑–∞—à–∏—Ñ—Ä–æ–≤–∞–Ω
    expires_at      TIMESTAMPTZ,
    account_subdomain VARCHAR(100),                 -- –¥–ª—è amoCRM, –ë–∏—Ç—Ä–∏–∫—Å24
    account_id      VARCHAR(100),
    is_active       BOOLEAN     NOT NULL DEFAULT TRUE,
    last_sync_at    TIMESTAMPTZ,
    created_at      TIMESTAMPTZ NOT NULL DEFAULT NOW(),
    updated_at      TIMESTAMPTZ NOT NULL DEFAULT NOW(),
    UNIQUE (user_id, crm_type)
);

CREATE INDEX idx_crm_connections_user_id ON crm_connections (user_id);
SELECT create_updated_at_trigger('crm_connections');

CREATE TABLE crm_sync_logs (
    id              UUID            PRIMARY KEY DEFAULT gen_random_uuid(),
    connection_id   UUID            NOT NULL REFERENCES crm_connections(id) ON DELETE CASCADE,
    direction       sync_direction  NOT NULL,
    entity_type     VARCHAR(50)     NOT NULL,   -- 'company' | 'contact' | 'deal'
    entity_id       UUID,
    external_id     VARCHAR(255),               -- ID –≤ CRM-—Å–∏—Å—Ç–µ–º–µ
    status          sync_status     NOT NULL DEFAULT 'pending',
    error_message   TEXT,
    records_synced  INTEGER         DEFAULT 0,
    synced_at       TIMESTAMPTZ     NOT NULL DEFAULT NOW()
);

CREATE INDEX idx_crm_sync_logs_connection ON crm_sync_logs (connection_id, synced_at DESC);

-- Billing
CREATE TYPE subscription_plan AS ENUM ('starter', 'growth', 'scale', 'enterprise');
CREATE TYPE subscription_status AS ENUM ('active', 'trialing', 'past_due', 'cancelled', 'expired');
CREATE TYPE payment_status AS ENUM ('pending', 'succeeded', 'failed', 'refunded');
CREATE TYPE payment_method AS ENUM ('card', 'bank_transfer', 'sbp', 'crypto');

CREATE TABLE subscriptions (
    id                      UUID                    PRIMARY KEY DEFAULT gen_random_uuid(),
    user_id                 UUID                    NOT NULL REFERENCES users(id),
    plan                    subscription_plan       NOT NULL DEFAULT 'starter',
    status                  subscription_status     NOT NULL DEFAULT 'trialing',
    trial_ends_at           TIMESTAMPTZ,
    current_period_start    TIMESTAMPTZ             NOT NULL DEFAULT NOW(),
    current_period_end      TIMESTAMPTZ             NOT NULL,
    cancel_at_period_end    BOOLEAN                 NOT NULL DEFAULT FALSE,
    cancelled_at            TIMESTAMPTZ,
    external_subscription_id VARCHAR(255),          -- ID –≤ –ÆKassa
    created_at              TIMESTAMPTZ             NOT NULL DEFAULT NOW(),
    updated_at              TIMESTAMPTZ             NOT NULL DEFAULT NOW()
);

CREATE UNIQUE INDEX idx_subscriptions_user_active
    ON subscriptions (user_id) WHERE status IN ('active', 'trialing', 'past_due');
SELECT create_updated_at_trigger('subscriptions');

CREATE TABLE payments (
    id                      UUID                PRIMARY KEY DEFAULT gen_random_uuid(),
    subscription_id         UUID                NOT NULL REFERENCES subscriptions(id),
    user_id                 UUID                NOT NULL REFERENCES users(id),
    amount                  BIGINT              NOT NULL CHECK (amount > 0),  -- –≤ –∫–æ–ø–µ–π–∫–∞—Ö
    currency                VARCHAR(3)          NOT NULL DEFAULT 'RUB',
    status                  payment_status      NOT NULL DEFAULT 'pending',
    payment_method          payment_method,
    external_payment_id     VARCHAR(255)        UNIQUE,
    description             VARCHAR(500),
    failure_reason          TEXT,
    paid_at                 TIMESTAMPTZ,
    created_at              TIMESTAMPTZ         NOT NULL DEFAULT NOW()
);

CREATE INDEX idx_payments_user_id        ON payments (user_id, created_at DESC);
CREATE INDEX idx_payments_subscription   ON payments (subscription_id);
CREATE INDEX idx_payments_status         ON payments (status) WHERE status = 'pending';


‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
–ß–ê–°–¢–¨ 5: CLICKHOUSE SCHEMA (–∞–Ω–∞–ª–∏—Ç–∏–∫–∞)
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

-- user_events: –≤—Å–µ –¥–µ–π—Å—Ç–≤–∏—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π
CREATE TABLE analytics.user_events (
    event_id        UUID,
    user_id         UUID,
    session_id      String,
    event_type      LowCardinality(String),  -- 'search', 'view_company', 'request_contact'
    properties      String,                  -- JSON —Å—Ç—Ä–æ–∫–∞
    page_url        String,
    referrer        String,
    ip_address      IPv4,
    user_agent      String,
    occurred_at     DateTime64(3, 'Europe/Moscow')
) ENGINE = MergeTree()
PARTITION BY toYYYYMM(occurred_at)
ORDER BY (user_id, occurred_at)
TTL occurred_at + INTERVAL 90 DAY;

-- search_queries: –≤—Å–µ –ø–æ–∏—Å–∫–æ–≤—ã–µ –∑–∞–ø—Ä–æ—Å—ã
CREATE TABLE analytics.search_queries (
    query_id        UUID,
    user_id         UUID,
    query_text      String,
    filters         String,                  -- JSON
    results_count   UInt32,
    clicked_ids     Array(UUID),
    response_ms     UInt32,
    occurred_at     DateTime64(3, 'Europe/Moscow')
) ENGINE = MergeTree()
PARTITION BY toYYYYMM(occurred_at)
ORDER BY (occurred_at, user_id)
TTL occurred_at + INTERVAL 180 DAY;

-- partnership_funnel: –≤–æ—Ä–æ–Ω–∫–∞ –ø–∞—Ä—Ç–Ω—ë—Ä—Å—Ç–≤
CREATE TABLE analytics.partnership_funnel (
    partnership_id  UUID,
    company_a_id    UUID,
    company_b_id    UUID,
    score           Float32,
    suggested_at    DateTime64(3, 'Europe/Moscow'),
    viewed_at       Nullable(DateTime64(3)),
    contacted_at    Nullable(DateTime64(3)),
    responded_at    Nullable(DateTime64(3)),
    deal_closed_at  Nullable(DateTime64(3)),
    deal_value_rub  Nullable(Int64)
) ENGINE = ReplacingMergeTree()
PARTITION BY toYYYYMM(suggested_at)
ORDER BY partnership_id;

-- Kafka ‚Üí ClickHouse –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —á–µ—Ä–µ–∑ Kafka Engine
CREATE TABLE analytics.kafka_events_queue (
    raw JSON
) ENGINE = Kafka()
SETTINGS
    kafka_broker_list = 'kafka:9092',
    kafka_topic_list  = 'user.created,company.created,partnership.matched',
    kafka_group_name  = 'clickhouse-analytics',
    kafka_format      = 'JSONEachRow';


‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
–ß–ê–°–¢–¨ 6: ALEMBIC –ú–ò–ì–†–ê–¶–ò–Ø (–ø—Ä–∏–º–µ—Ä)
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

## services/company-service/alembic/versions/0001_companies_table.py:

"""Create companies tables

Revision ID: 0001
Revises:
Create Date: 2026-02-11
"""

from alembic import op
import sqlalchemy as sa
from pgvector.sqlalchemy import Vector

revision = '0001'
down_revision = None
branch_labels = None
depends_on = None


def upgrade() -> None:
    # –í–∫–ª—é—á–∞–µ–º —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—è
    op.execute("CREATE EXTENSION IF NOT EXISTS \"uuid-ossp\"")
    op.execute("CREATE EXTENSION IF NOT EXISTS \"pgvector\"")
    op.execute("CREATE EXTENSION IF NOT EXISTS \"pg_cron\"")

    # –°–æ–∑–¥–∞—ë–º —Ñ—É–Ω–∫—Ü–∏—é set_updated_at
    op.execute("""
        CREATE OR REPLACE FUNCTION set_updated_at()
        RETURNS TRIGGER AS $$
        BEGIN NEW.updated_at = NOW(); RETURN NEW; END;
        $$ LANGUAGE plpgsql;
    """)

    # Enum —Ç–∏–ø—ã
    op.execute("""
        DO $$ BEGIN
            CREATE TYPE funding_stage AS ENUM (
                'pre_seed','seed','series_a','series_b','series_c',
                'series_d_plus','ipo','bootstrapped','unknown'
            );
        EXCEPTION WHEN duplicate_object THEN NULL; END $$;
    """)
    op.execute("""
        DO $$ BEGIN
            CREATE TYPE employees_range AS ENUM (
                '1-10','11-50','51-200','201-500','500+'
            );
        EXCEPTION WHEN duplicate_object THEN NULL; END $$;
    """)

    # –¢–∞–±–ª–∏—Ü–∞ companies
    op.create_table(
        'companies',
        sa.Column('id',           sa.UUID(as_uuid=True), primary_key=True,
                  server_default=sa.text('gen_random_uuid()')),
        sa.Column('name',         sa.String(255), nullable=False),
        sa.Column('slug',         sa.String(255), nullable=False, unique=True),
        sa.Column('description',  sa.Text),
        sa.Column('website',      sa.String(500)),
        sa.Column('industry',     sa.String(100), nullable=False),
        sa.Column('sub_industries', sa.ARRAY(sa.Text), nullable=False,
                  server_default='{}'),
        sa.Column('founded_year', sa.SmallInteger,
                  sa.CheckConstraint('founded_year BETWEEN 1900 AND 2030')),
        sa.Column('headquarters_country', sa.String(10), nullable=False,
                  server_default='RU'),
        sa.Column('headquarters_city',    sa.String(100)),
        sa.Column('employees_range', sa.Enum('1-10','11-50','51-200','201-500','500+',
                  name='employees_range', create_type=False)),
        sa.Column('funding_total',    sa.BigInteger),
        sa.Column('funding_currency', sa.String(3),  nullable=False,
                  server_default='RUB'),
        sa.Column('funding_stage', sa.Enum('pre_seed','seed','series_a','series_b',
                  'series_c','series_d_plus','ipo','bootstrapped','unknown',
                  name='funding_stage', create_type=False), server_default='unknown'),
        sa.Column('inn',          sa.String(12), unique=True),
        sa.Column('ogrn',         sa.String(15), unique=True),
        sa.Column('legal_name',   sa.String(500)),
        sa.Column('tech_stack',   sa.JSON,        nullable=False, server_default='{}'),
        sa.Column('integrations', sa.ARRAY(sa.Text), nullable=False, server_default='{}'),
        sa.Column('api_available',sa.Boolean,     nullable=False, server_default='false'),
        sa.Column('ai_summary',   sa.Text),
        sa.Column('ai_tags',      sa.ARRAY(sa.Text), nullable=False, server_default='{}'),
        sa.Column('embedding',    Vector(768)),
        sa.Column('is_verified',  sa.Boolean,     nullable=False, server_default='false'),
        sa.Column('view_count',   sa.Integer,     nullable=False, server_default='0'),
        sa.Column('created_at',   sa.DateTime(timezone=True), nullable=False,
                  server_default=sa.func.now()),
        sa.Column('updated_at',   sa.DateTime(timezone=True), nullable=False,
                  server_default=sa.func.now()),
        sa.Column('deleted_at',   sa.DateTime(timezone=True)),
    )

    # –ò–Ω–¥–µ–∫—Å—ã
    op.create_index('idx_companies_industry',
        'companies', ['industry'],
        postgresql_where=sa.text('deleted_at IS NULL'))
    op.create_index('idx_companies_sub_industries',
        'companies', ['sub_industries'],
        postgresql_using='gin')
    op.create_index('idx_companies_tech_stack',
        'companies', [sa.text("tech_stack")],
        postgresql_using='gin')
    op.create_index('idx_companies_ai_tags',
        'companies', ['ai_tags'],
        postgresql_using='gin')

    # IVFFlat vector index
    op.execute("""
        CREATE INDEX idx_companies_embedding
        ON companies
        USING ivfflat (embedding vector_cosine_ops)
        WITH (lists = 100)
        WHERE embedding IS NOT NULL;
    """)

    # –¢—Ä–∏–≥–≥–µ—Ä updated_at
    op.execute("""
        CREATE TRIGGER set_updated_at
        BEFORE UPDATE ON companies
        FOR EACH ROW EXECUTE FUNCTION set_updated_at();
    """)


def downgrade() -> None:
    op.drop_table('companies')
    op.execute("DROP TYPE IF EXISTS funding_stage")
    op.execute("DROP TYPE IF EXISTS employees_range")


‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
–ß–ê–°–¢–¨ 7: SQLALCHEMY 2.0 –ú–û–î–ï–õ–ò
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

## services/company-service/src/infrastructure/models.py:

from datetime import datetime, date
from uuid import UUID, uuid4
from typing import Any
import sqlalchemy as sa
from sqlalchemy.orm import DeclarativeBase, Mapped, mapped_column
from sqlalchemy.dialects.postgresql import ARRAY, JSONB, UUID as PG_UUID
from pgvector.sqlalchemy import Vector


class Base(DeclarativeBase):
    pass


class CompanyORM(Base):
    __tablename__ = "companies"

    id: Mapped[UUID] = mapped_column(
        PG_UUID(as_uuid=True), primary_key=True, default=uuid4
    )
    name: Mapped[str] = mapped_column(sa.String(255), nullable=False)
    slug: Mapped[str] = mapped_column(sa.String(255), nullable=False, unique=True)
    description: Mapped[str | None] = mapped_column(sa.Text)
    website: Mapped[str | None] = mapped_column(sa.String(500))
    industry: Mapped[str] = mapped_column(sa.String(100), nullable=False)
    sub_industries: Mapped[list[str]] = mapped_column(
        ARRAY(sa.Text), nullable=False, server_default=sa.text("'{}'::text[]")
    )
    founded_year: Mapped[int | None] = mapped_column(sa.SmallInteger)
    headquarters_country: Mapped[str] = mapped_column(
        sa.String(10), nullable=False, server_default="RU"
    )
    headquarters_city: Mapped[str | None] = mapped_column(sa.String(100))
    employees_range: Mapped[str | None] = mapped_column(
        sa.Enum("1-10", "11-50", "51-200", "201-500", "500+", name="employees_range")
    )
    funding_total: Mapped[int | None] = mapped_column(sa.BigInteger)   # –≤ –∫–æ–ø–µ–π–∫–∞—Ö
    funding_currency: Mapped[str] = mapped_column(
        sa.String(3), nullable=False, server_default="RUB"
    )
    funding_stage: Mapped[str] = mapped_column(
        sa.Enum("pre_seed", "seed", "series_a", "series_b", "series_c",
                "series_d_plus", "ipo", "bootstrapped", "unknown",
                name="funding_stage"),
        server_default="unknown"
    )
    inn: Mapped[str | None] = mapped_column(sa.String(12), unique=True)
    ogrn: Mapped[str | None] = mapped_column(sa.String(15), unique=True)
    legal_name: Mapped[str | None] = mapped_column(sa.String(500))
    tech_stack: Mapped[dict[str, Any]] = mapped_column(
        JSONB, nullable=False, server_default=sa.text("'{}'::jsonb")
    )
    integrations: Mapped[list[str]] = mapped_column(
        ARRAY(sa.Text), nullable=False, server_default=sa.text("'{}'::text[]")
    )
    api_available: Mapped[bool] = mapped_column(
        sa.Boolean, nullable=False, server_default="false"
    )
    ai_summary: Mapped[str | None] = mapped_column(sa.Text)
    ai_tags: Mapped[list[str]] = mapped_column(
        ARRAY(sa.Text), nullable=False, server_default=sa.text("'{}'::text[]")
    )
    embedding: Mapped[list[float] | None] = mapped_column(Vector(768))
    is_verified: Mapped[bool] = mapped_column(
        sa.Boolean, nullable=False, server_default="false"
    )
    view_count: Mapped[int] = mapped_column(
        sa.Integer, nullable=False, server_default="0"
    )
    created_at: Mapped[datetime] = mapped_column(
        sa.DateTime(timezone=True), server_default=sa.func.now()
    )
    updated_at: Mapped[datetime] = mapped_column(
        sa.DateTime(timezone=True), server_default=sa.func.now(),
        onupdate=sa.func.now()
    )
    deleted_at: Mapped[datetime | None] = mapped_column(sa.DateTime(timezone=True))

    __table_args__ = (
        sa.CheckConstraint("founded_year BETWEEN 1900 AND 2030", name="ck_founded_year"),
    )


## services/auth-service/src/infrastructure/models.py:

class UserORM(Base):
    __tablename__ = "users"

    id: Mapped[UUID] = mapped_column(
        PG_UUID(as_uuid=True), primary_key=True, default=uuid4
    )
    email: Mapped[str] = mapped_column(
        sa.String(255), nullable=False, unique=True, index=True
    )
    password_hash: Mapped[str] = mapped_column(sa.String(72), nullable=False)
    full_name: Mapped[str] = mapped_column(sa.String(255), nullable=False)
    company_name: Mapped[str | None] = mapped_column(sa.String(255))
    role: Mapped[str] = mapped_column(
        sa.Enum("free_user", "paid_user", "company_admin", "platform_admin",
                name="user_role"),
        nullable=False, server_default="free_user"
    )
    is_active: Mapped[bool] = mapped_column(
        sa.Boolean, nullable=False, server_default="false"
    )
    is_verified: Mapped[bool] = mapped_column(
        sa.Boolean, nullable=False, server_default="false"
    )
    totp_secret: Mapped[str | None] = mapped_column(sa.String(32))
    totp_enabled: Mapped[bool] = mapped_column(
        sa.Boolean, nullable=False, server_default="false"
    )
    last_login_at: Mapped[datetime | None] = mapped_column(sa.DateTime(timezone=True))
    failed_login_count: Mapped[int] = mapped_column(
        sa.Integer, nullable=False, server_default="0"
    )
    created_at: Mapped[datetime] = mapped_column(
        sa.DateTime(timezone=True), server_default=sa.func.now()
    )
    updated_at: Mapped[datetime] = mapped_column(
        sa.DateTime(timezone=True), server_default=sa.func.now(),
        onupdate=sa.func.now()
    )
    deleted_at: Mapped[datetime | None] = mapped_column(sa.DateTime(timezone=True))


class RefreshTokenORM(Base):
    __tablename__ = "refresh_tokens"

    id: Mapped[UUID] = mapped_column(
        PG_UUID(as_uuid=True), primary_key=True, default=uuid4
    )
    user_id: Mapped[UUID] = mapped_column(
        PG_UUID(as_uuid=True),
        sa.ForeignKey("users.id", ondelete="CASCADE"), nullable=False
    )
    token_hash: Mapped[str] = mapped_column(sa.String(64), nullable=False, unique=True)
    expires_at: Mapped[datetime] = mapped_column(
        sa.DateTime(timezone=True), nullable=False
    )
    created_at: Mapped[datetime] = mapped_column(
        sa.DateTime(timezone=True), server_default=sa.func.now()
    )
    revoked_at: Mapped[datetime | None] = mapped_column(sa.DateTime(timezone=True))


‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
–ß–ê–°–¢–¨ 8: SEED DATA SCRIPT
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

## scripts/seed_data.py:

#!/usr/bin/env python3
"""
–ó–∞–≥—Ä—É–∑–∫–∞ —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö: –∫–æ–º–ø–∞–Ω–∏–∏, –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–∏, –ø–∞—Ä—Ç–Ω—ë—Ä—Å—Ç–≤–∞.
–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ: python seed_data.py --count=100
"""

import asyncio
import argparse
import random
from uuid import uuid4
from datetime import datetime, timedelta
from passlib.context import CryptContext
import asyncpg

INDUSTRIES = [
    "SaaS", "Fintech", "Edtech", "Healthtech", "Martech",
    "HRtech", "Logtech", "Proptech", "Legaltech", "Cybersecurity"
]

CITIES = ["–ú–æ—Å–∫–≤–∞", "–°–∞–Ω–∫—Ç-–ü–µ—Ç–µ—Ä–±—É—Ä–≥", "–ù–æ–≤–æ—Å–∏–±–∏—Ä—Å–∫", "–ï–∫–∞—Ç–µ—Ä–∏–Ω–±—É—Ä–≥",
          "–ö–∞–∑–∞–Ω—å", "–ù–∏–∂–Ω–∏–π –ù–æ–≤–≥–æ—Ä–æ–¥", "–°–∞–º–∞—Ä–∞", "–£—Ñ–∞"]

TECH_STACKS = [
    {"python": True, "react": True, "postgresql": True},
    {"python": True, "vue": True, "postgresql": True, "redis": True},
    {"golang": True, "react": True, "mongodb": True},
    {"java": True, "angular": True, "mysql": True},
    {"python": True, "django": True, "postgresql": True, "celery": True},
    {"nodejs": True, "react": True, "mongodb": True, "redis": True},
]

INTEGRATIONS = [
    ["Slack", "Salesforce"], ["Bitrix24", "amoCRM"],
    ["Slack", "HubSpot", "Zapier"], ["1C", "–ú–æ–π–°–∫–ª–∞–¥"],
    ["Telegram", "WhatsApp Business"], ["Jira", "Confluence"],
]

FUNDING_STAGES = [
    "pre_seed", "seed", "series_a", "bootstrapped", "unknown"
]

pwd_ctx = CryptContext(schemes=["bcrypt"], deprecated="auto")


async def seed_companies(conn: asyncpg.Connection, count: int):
    print(f"  ‚Üí –°–æ–∑–¥–∞–Ω–∏–µ {count} –∫–æ–º–ø–∞–Ω–∏–π...")
    for i in range(count):
        industry = random.choice(INDUSTRIES)
        city = random.choice(CITIES)
        name = f"SaaS Company {i+1:03d}"
        slug = f"saas-company-{i+1:03d}"

        await conn.execute("""
            INSERT INTO companies (
                id, name, slug, description, industry, sub_industries,
                headquarters_country, headquarters_city,
                employees_range, funding_stage, tech_stack,
                integrations, api_available, is_verified,
                founded_year, created_at, updated_at
            ) VALUES ($1,$2,$3,$4,$5,$6,$7,$8,$9,$10,$11,$12,$13,$14,$15,NOW(),NOW())
            ON CONFLICT (slug) DO NOTHING
        """,
            uuid4(),
            name,
            slug,
            f"–†–æ—Å—Å–∏–π—Å–∫–∞—è SaaS-–∫–æ–º–ø–∞–Ω–∏—è –≤ —Å—Ñ–µ—Ä–µ {industry}. "
            f"–ü–æ–º–æ–≥–∞–µ–º –±–∏–∑–Ω–µ—Å—É –∞–≤—Ç–æ–º–∞—Ç–∏–∑–∏—Ä–æ–≤–∞—Ç—å –ø—Ä–æ—Ü–µ—Å—Å—ã.",
            industry,
            random.sample(INDUSTRIES, k=random.randint(1, 3)),
            "RU",
            city,
            random.choice(["1-10", "11-50", "51-200"]),
            random.choice(FUNDING_STAGES),
            random.choice(TECH_STACKS),       # JSONB
            random.choice(INTEGRATIONS),       # TEXT[]
            random.random() > 0.5,             # api_available
            random.random() > 0.7,             # is_verified
            random.randint(2015, 2024),        # founded_year
        )
    print(f"  ‚úÖ {count} –∫–æ–º–ø–∞–Ω–∏–π —Å–æ–∑–¥–∞–Ω–æ")


async def seed_users(conn: asyncpg.Connection, count: int = 50):
    print(f"  ‚Üí –°–æ–∑–¥–∞–Ω–∏–µ {count} –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π...")
    for i in range(count):
        role = "paid_user" if i < 40 else "company_admin"
        await conn.execute("""
            INSERT INTO users (
                id, email, password_hash, full_name, company_name,
                role, is_active, is_verified, created_at, updated_at
            ) VALUES ($1,$2,$3,$4,$5,$6,TRUE,TRUE,NOW(),NOW())
            ON CONFLICT (email) DO NOTHING
        """,
            uuid4(),
            f"user{i+1:03d}@algorithmic-arts-test.ru",
            pwd_ctx.hash("TestPassword123"),
            f"–¢–µ—Å—Ç–æ–≤—ã–π –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å {i+1}",
            f"–û–û–û –¢–µ—Å—Ç –ö–æ–º–ø–∞–Ω–∏—è {i+1}",
            role,
        )
    # –û—Ç–¥–µ–ª—å–Ω–æ —Å–æ–∑–¥–∞—ë–º admin
    await conn.execute("""
        INSERT INTO users (id, email, password_hash, full_name, role,
                           is_active, is_verified, created_at, updated_at)
        VALUES ($1,$2,$3,'Platform Admin','platform_admin',TRUE,TRUE,NOW(),NOW())
        ON CONFLICT (email) DO NOTHING
    """,
        uuid4(),
        "admin@algorithmic-arts.ru",
        pwd_ctx.hash("AdminPassword123!"),
    )
    print(f"  ‚úÖ {count+1} –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π —Å–æ–∑–¥–∞–Ω–æ (–≤–∫–ª—é—á–∞—è admin)")


async def seed_partnerships(conn: asyncpg.Connection, count: int = 200):
    print(f"  ‚Üí –°–æ–∑–¥–∞–Ω–∏–µ {count} –ø–∞—Ä—Ç–Ω—ë—Ä—Å—Ç–≤...")
    companies = await conn.fetch("SELECT id FROM companies LIMIT 100")
    company_ids = [r['id'] for r in companies]

    created = 0
    attempts = 0
    while created < count and attempts < count * 3:
        a, b = random.sample(company_ids, 2)
        if a > b:
            a, b = b, a
        score = round(random.uniform(0.5, 0.98), 4)
        try:
            await conn.execute("""
                INSERT INTO partnerships (
                    id, company_a_id, company_b_id, compatibility_score,
                    status, analysis_method, created_at, updated_at
                ) VALUES ($1,$2,$3,$4,$5,'auto_vector_scoring',NOW(),NOW())
                ON CONFLICT DO NOTHING
            """, uuid4(), a, b, score,
                random.choice(["suggested", "reviewed", "contacted"]))
            created += 1
        except Exception:
            pass
        attempts += 1
    print(f"  ‚úÖ {created} –ø–∞—Ä—Ç–Ω—ë—Ä—Å—Ç–≤ —Å–æ–∑–¥–∞–Ω–æ")


async def main(count: int):
    conn = await asyncpg.connect(
        host="localhost", port=5432,
        user="algo_user", password="REPLACE_ME",
        database="algorithmic_arts"
    )
    print("üå± –ó–∞–≥—Ä—É–∑–∫–∞ seed-–¥–∞–Ω–Ω—ã—Ö...")
    await seed_users(conn)
    await seed_companies(conn, count)
    await seed_partnerships(conn, count * 2)
    await conn.close()
    print("‚úÖ Seed-–¥–∞–Ω–Ω—ã–µ –∑–∞–≥—Ä—É–∂–µ–Ω—ã —É—Å–ø–µ—à–Ω–æ!")


if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument("--count", type=int, default=100)
    args = parser.parse_args()
    asyncio.run(main(args.count))


–û–ë–©–ò–ï –¢–†–ï–ë–û–í–ê–ù–ò–Ø:
- –í—Å–µ —Ç–∞–±–ª–∏—Ü—ã: created_at, updated_at (—Å —Ç—Ä–∏–≥–≥–µ—Ä–æ–º), soft delete —á–µ—Ä–µ–∑ deleted_at
- –ö–∞–∂–¥—ã–π FK —Å–æ–ø—Ä–æ–≤–æ–∂–¥—ë–Ω –∏–Ω–¥–µ–∫—Å–æ–º
- Enum-—Ç–∏–ø—ã —Å–æ–∑–¥–∞—é—Ç—Å—è —á–µ—Ä–µ–∑ DO $$ ... EXCEPTION WHEN duplicate_object THEN NULL $$
- Alembic env.py: async –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ —á–µ—Ä–µ–∑ asyncpg, –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π
- –ú–∏–≥—Ä–∞—Ü–∏–∏ –∏–¥–µ–º–ø–æ—Ç–µ–Ω—Ç–Ω—ã (–ø–æ–≤—Ç–æ—Ä–Ω—ã–π –∑–∞–ø—É—Å–∫ –Ω–µ –ª–æ–º–∞–µ—Ç –ë–î)
- SQLAlchemy –º–æ–¥–µ–ª–∏: —Å—Ç—Ä–æ–≥–æ Mapped[...] —Å–∏–Ω—Ç–∞–∫—Å–∏—Å, –±–µ–∑ Column() —Å—Ç–∞—Ä–æ–≥–æ —Å—Ç–∏–ª—è
- Seed-—Å–∫—Ä–∏–ø—Ç: –ø—Ä–∏–Ω–∏–º–∞–µ—Ç --count, —Ä–∞–±–æ—Ç–∞–µ—Ç idempotently (ON CONFLICT DO NOTHING)

–°–æ–∑–¥–∞–π –≤—Å–µ —Ñ–∞–π–ª—ã: SQL —Å—Ö–µ–º—ã, Alembic-–º–∏–≥—Ä–∞—Ü–∏–∏ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —Å–µ—Ä–≤–∏—Å–∞,
SQLAlchemy –º–æ–¥–µ–ª–∏, ClickHouse DDL –∏ seed_data.py.
```

---

## –ß–µ–∫–ª–∏—Å—Ç —É–ª—É—á—à–µ–Ω–∏–π –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ –∏—Å—Ö–æ–¥–Ω—ã—Ö –ø—Ä–æ–º–ø—Ç–æ–≤

### –ü—Ä–æ–º–ø—Ç ‚Ññ1 ‚Äî —á—Ç–æ –¥–æ–±–∞–≤–ª–µ–Ω–æ:
- –ü–æ–ª–Ω–∞—è —Ñ–∞–π–ª–æ–≤–∞—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∞ —Å –ø–µ—Ä–µ—á–Ω–µ–º –∫–∞–∂–¥–æ–≥–æ —Ñ–∞–π–ª–∞ –∏ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏—è–º–∏
- –¢–∞–±–ª–∏—Ü–∞ –≤—Å–µ—Ö —Å–µ—Ä–≤–∏—Å–æ–≤ —Å –ø–æ—Ä—Ç–∞–º–∏ –∏ —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏—è–º–∏
- –î–≤—É—Ö—Å–µ—Ä–≤–µ—Ä–Ω—ã–π Dockerfile (development + production) —Å healthcheck –∏ –Ω–µ–ø—Ä–∏–≤–∏–ª–µ–≥–∏—Ä–æ–≤–∞–Ω–Ω—ã–º –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º
- Dockerfile –¥–ª—è Next.js 15 (3 —Å—Ç–∞–¥–∏–∏: deps ‚Üí builder ‚Üí production —Å standalone output)
- –ü–æ–ª–Ω—ã–π `.env.example` (35+ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö, 12 —Å–µ–∫—Ü–∏–π: DB, Redis, Kafka, MinIO, ClickHouse, JWT, YandexGPT, GigaChat, OpenRouter, CRM, Email, Payments)
- –†–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π Makefile (25+ –∫–æ–º–∞–Ω–¥: start-infra, restart-svc, logs-svc, migrate-svc, rollback, migration-new, test-coverage, test-load, lint, format, seed, create-admin)
- `scripts/generate_secrets.py` —Å RSA key pair + —Å–ª—É—á–∞–π–Ω—ã–µ –ø–∞—Ä–æ–ª–∏
- `scripts/check_dependencies.sh` —Å –ø—Ä–æ–≤–µ—Ä–∫–æ–π –≤–µ—Ä—Å–∏–π
- `infra/postgres/init.sql` —Å —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—è–º–∏ –∏ —Ñ—É–Ω–∫—Ü–∏–µ–π `set_updated_at()`
- `infra/kafka/topics.sh` —Å —Å–æ–∑–¥–∞–Ω–∏–µ–º –≤—Å–µ—Ö 18 —Ç–æ–ø–∏–∫–æ–≤
- `docker-compose.override.yml` (dev volume mounts, hot reload)

### –ü—Ä–æ–º–ø—Ç ‚Ññ2 ‚Äî —á—Ç–æ –¥–æ–±–∞–≤–ª–µ–Ω–æ:
- –ü–æ–ª–Ω—ã–π SQL DDL –¥–ª—è 14 —Ç–∞–±–ª–∏—Ü (–≤—Å–µ –ø–æ–ª—è, —Ç–∏–ø—ã, constraints)
- 10 Enum-—Ç–∏–ø–æ–≤ PostgreSQL —Å –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–π –∏–¥–µ–º–ø–æ—Ç–µ–Ω—Ç–Ω–æ–π –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–µ–π
- 35+ –∏–Ω–¥–µ–∫—Å–æ–≤: B-tree, GIN (JSONB/–º–∞—Å—Å–∏–≤—ã), IVFFlat (pgvector), partial (WHERE conditions)
- –ü–∞—Ä—Ç–∏—Ü–∏–æ–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ company_updates –ø–æ –∫–≤–∞—Ä—Ç–∞–ª–∞–º (2025-2026), company_metrics –ø–æ –≥–æ–¥–∞–º
- pg_cron: –∞–≤—Ç–æ–æ—á–∏—Å—Ç–∫–∞ –ø—Ä–æ—Å—Ä–æ—á–µ–Ω–Ω—ã—Ö —Ç–æ–∫–µ–Ω–æ–≤ –∏ refresh tokens
- Constraint –¥–ª—è —É–Ω–∏–∫–∞–ª—å–Ω–æ—Å—Ç–∏ –ø–∞—Ä –∫–æ–º–ø–∞–Ω–∏–π –≤ –ø–∞—Ä—Ç–Ω—ë—Ä—Å—Ç–≤–∞—Ö (`CHECK (company_a_id < company_b_id)`)
- –ü–æ–ª–Ω–∞—è Alembic-–º–∏–≥—Ä–∞—Ü–∏—è —Å —Ä–µ–∞–ª—å–Ω—ã–º Python-–∫–æ–¥–æ–º (upgrade/downgrade)
- SQLAlchemy 2.0 –º–æ–¥–µ–ª–∏ –¥–ª—è Company –∏ User (Mapped[] —Å–∏–Ω—Ç–∞–∫—Å–∏—Å, –≤—Å–µ —Ç–∏–ø—ã)
- ClickHouse DDL: 3 —Ç–∞–±–ª–∏—Ü—ã (user_events, search_queries, partnership_funnel) + Kafka Engine
- –ü–æ–ª–Ω—ã–π seed_data.py: –∫–æ–º–ø–∞–Ω–∏–∏ (100+), –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–∏ (50+), –ø–∞—Ä—Ç–Ω—ë—Ä—Å—Ç–≤–∞ (200+), —Å ON CONFLICT DO NOTHING
